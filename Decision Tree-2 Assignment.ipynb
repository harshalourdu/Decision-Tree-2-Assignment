{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Import the dataset and examine the variables\n",
    "\n",
    "# To begin, we will load the dataset and explore it using descriptive statistics and visualizations. This helps us understand the distribution of the data and relationships between the variables.\n",
    "\n",
    "# Code Example:\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Display summary statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Visualize the distribution of each feature\n",
    "df.hist(figsize=(12, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize the correlation matrix to identify relationships\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the distribution of the target variable (Outcome)\n",
    "sns.countplot(x='Outcome', data=df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. Preprocess the data\n",
    "# Before training the model, we need to preprocess the data:\n",
    "\n",
    "# Handle missing values: Some columns may have missing values that need to be filled or removed.\n",
    "# Remove outliers: Outliers may affect model performance.\n",
    "# Transform categorical variables: In this dataset, the \"Outcome\" variable is the target, but we may need to handle other categorical features if present (none in this case).\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values by replacing with the mean (or other imputation methods)\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "# Check for outliers using boxplots\n",
    "sns.boxplot(x=df['Glucose'])\n",
    "plt.show()\n",
    "\n",
    "# Remove outliers (example: removing values beyond the 95th percentile)\n",
    "df = df[df['Glucose'] < df['Glucose'].quantile(0.95)]\n",
    "\n",
    "# Check the data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Ensure all variables are numeric (already true in this dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. Split the dataset into training and test sets\n",
    "# We will split the dataset into a training set and a test set to train and evaluate the model. Using a random seed ensures reproducibility.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Train a decision tree model\n",
    "# We will use a decision tree algorithm such as ID3 or C4.5 (scikit-learnâ€™s DecisionTreeClassifier implements C4.5), and we will perform cross-validation to optimize the model's hyperparameters.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize a DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'max_depth': [3, 5, 7, 10, None],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4],\n",
    "              'criterion': ['gini', 'entropy']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_dt = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Evaluate the performance of the decision tree\n",
    "# After training the model, we evaluate its performance on the test set using metrics like accuracy, precision, recall, and F1 score. We will also use a confusion matrix and ROC curve to visualize the results.\n",
    "\n",
    "# Code Example:\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')\n",
    "print(f'ROC AUC: {roc_auc:.2f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Diabetic', 'Diabetic'], yticklabels=['Non-Diabetic', 'Diabetic'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, best_dt.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Interpret the decision tree\n",
    "# After training the decision tree, we can visualize the tree to understand the splits, branches, and leaves. We can also determine the most important features.\n",
    "\n",
    "# Code Example:\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Visualize the trained decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "plot_tree(best_dt, filled=True, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], rounded=True)\n",
    "plt.show()\n",
    "\n",
    "# Feature importance\n",
    "importances = best_dt.feature_importances_\n",
    "feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importances})\n",
    "print(feature_importance.sort_values(by='Importance', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Validate the decision tree model\n",
    "# Finally, we can validate the model by applying it to new data or testing its robustness to changes in the dataset or environment. Sensitivity analysis can also be used to check how the model responds to small changes in input data.\n",
    "\n",
    "# Code Example:\n",
    "\n",
    "# Sensitivity analysis: Try slightly modifying the test set\n",
    "X_test_modified = X_test.copy()\n",
    "X_test_modified['Glucose'] += 5  # Slight modification\n",
    "y_pred_modified = best_dt.predict(X_test_modified)\n",
    "\n",
    "# Evaluate the performance again\n",
    "accuracy_modified = accuracy_score(y_test, y_pred_modified)\n",
    "print(f'Accuracy on modified test set: {accuracy_modified:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
